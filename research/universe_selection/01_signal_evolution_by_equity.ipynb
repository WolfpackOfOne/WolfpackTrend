{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Evolution by Equity\n",
    "\n",
    "Use this notebook to see how each symbol's signal moves over time and which signal component drives it.\n",
    "\n",
    "Questions this answers:\n",
    "- Are signals stable or noisy by symbol?\n",
    "- Are short/medium/long components aligned?\n",
    "- Which symbols have persistent high-magnitude signals?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "from QuantConnect import *\n",
    "from QuantConnect.Research import QuantBook\n",
    "from config import TEAM_ID, ALPHA_SIGNAL_WEIGHTS, ALPHA_SIGNAL_TEMPERATURE, ALPHA_MIN_MAGNITUDE\n",
    "\n",
    "qb = QuantBook()\n",
    "print('QuantBook initialized')\n",
    "\n",
    "\n",
    "def read_csv_from_store(key):\n",
    "    try:\n",
    "        if not qb.ObjectStore.ContainsKey(key):\n",
    "            print(f'ObjectStore key not found: {key}')\n",
    "            return None\n",
    "        content = qb.ObjectStore.Read(key)\n",
    "        if not content:\n",
    "            print(f'Empty ObjectStore key: {key}')\n",
    "            return None\n",
    "        return pd.read_csv(StringIO(content))\n",
    "    except Exception as e:\n",
    "        print(f'Error reading {key}: {e}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signals = read_csv_from_store(f'{TEAM_ID}/signals.csv')\n",
    "\n",
    "if df_signals is None:\n",
    "    raise ValueError('signals.csv is required. Run a backtest first.')\n",
    "\n",
    "required_cols = ['date', 'symbol', 'direction', 'magnitude', 'price', 'sma_short', 'sma_medium', 'sma_long', 'atr']\n",
    "missing = [c for c in required_cols if c not in df_signals.columns]\n",
    "if missing:\n",
    "    raise ValueError(f'signals.csv missing required columns: {missing}')\n",
    "\n",
    "df = df_signals.copy()\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "for col in ['magnitude', 'price', 'sma_short', 'sma_medium', 'sma_long', 'atr']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df['direction'] = df['direction'].astype(str).str.title()\n",
    "df['direction_sign'] = np.where(df['direction'].eq('Up'), 1.0, -1.0)\n",
    "df['signed_magnitude'] = np.where(df['direction_sign'] > 0, df['magnitude'].abs(), -df['magnitude'].abs())\n",
    "df['abs_magnitude'] = df['signed_magnitude'].abs()\n",
    "\n",
    "# Mirror alpha model constants from shared config.py\n",
    "WEIGHT_SHORT, WEIGHT_MEDIUM, WEIGHT_LONG = ALPHA_SIGNAL_WEIGHTS\n",
    "SIGNAL_TEMPERATURE = ALPHA_SIGNAL_TEMPERATURE\n",
    "\n",
    "safe_atr = df['atr'].replace(0, np.nan)\n",
    "df['dist_short'] = (df['price'] - df['sma_short']) / safe_atr\n",
    "df['dist_medium'] = (df['price'] - df['sma_medium']) / safe_atr\n",
    "df['dist_long'] = (df['price'] - df['sma_long']) / safe_atr\n",
    "\n",
    "df['contrib_short'] = WEIGHT_SHORT * df['dist_short']\n",
    "df['contrib_medium'] = WEIGHT_MEDIUM * df['dist_medium']\n",
    "df['contrib_long'] = WEIGHT_LONG * df['dist_long']\n",
    "df['composite_score'] = df['contrib_short'] + df['contrib_medium'] + df['contrib_long']\n",
    "df['implied_magnitude'] = np.tanh(df['composite_score'] / SIGNAL_TEMPERATURE)\n",
    "\n",
    "df['all_trends_aligned'] = (\n",
    "    ((df['dist_short'] > 0) & (df['dist_medium'] > 0) & (df['dist_long'] > 0)) |\n",
    "    ((df['dist_short'] < 0) & (df['dist_medium'] < 0) & (df['dist_long'] < 0))\n",
    ")\n",
    "df['parity_abs_error'] = (df['signed_magnitude'] - df['implied_magnitude']).abs()\n",
    "\n",
    "df = df.sort_values(['symbol', 'date']).reset_index(drop=True)\n",
    "print(f'Alpha params from config: weights={ALPHA_SIGNAL_WEIGHTS}, temperature={ALPHA_SIGNAL_TEMPERATURE}, min_magnitude={ALPHA_MIN_MAGNITUDE}')\n",
    "print(f'Signal rows: {len(df):,}')\n",
    "print(f'Symbols: {df[\"symbol\"].nunique()}')\n",
    "print(f'Date range: {df[\"date\"].min().date()} to {df[\"date\"].max().date()}')\n",
    "print(f'All-horizon agreement (rounded inputs): {100 * df[\"all_trends_aligned\"].mean():.1f}%')\n",
    "print(f'Median |logged - implied|: {df[\"parity_abs_error\"].median():.4f}')\n",
    "print(f'95th pct |logged - implied|: {df[\"parity_abs_error\"].quantile(0.95):.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4jiccgnfv7h",
   "source": [
    "## Symbol Signal Summary Table\n",
    "\n",
    "This table summarizes each symbol's signal history: total observations, mean and median absolute magnitude, signal volatility, last signal date, and number of direction flips during the backtest. Symbols with high mean magnitude and few direction flips are persistent trend signals; symbols with frequent flips are noise-prone and may warrant closer monitoring. The table also determines which symbols to include in the charts below \u2014 either a custom focus list or the top 12 by frequency."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "s5id2w38dmk",
   "source": [
    "## Signal Magnitude Heatmap by Symbol\n",
    "\n",
    "This heatmap displays signed signal magnitude for each selected symbol across every rebalance date, with green indicating a long signal and red a short signal. Horizontal stripes of consistent color identify symbols with stable directional trends, while rapidly alternating red/green cells flag noisy or frequently reversing signals. Color intensity encodes signal strength, so pale cells near white represent weak or borderline signals close to the 0.05 minimum threshold."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "bdplao4h6yf",
   "source": [
    "## Per-Symbol Signal Path Grid\n",
    "\n",
    "This grid of small-multiple charts plots logged signed signal magnitude and a re-derived magnitude from the production alpha formula:\n",
    "\n",
    "`score = w_short*dist_short + w_medium*dist_medium + w_long*dist_long` and `magnitude = tanh(score / temperature)`,\n",
    "with `w_short/w_medium/w_long` and `temperature` loaded from `config.py`.\n",
    "\n",
    "Points are rebalance snapshots (not daily recomputes). Comparing the two lines shows whether the notebook reconstruction matches logged output; persistent gaps suggest rounding effects or a logging/parity issue.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "price_ma_diagnostic_section",
   "metadata": {},
   "source": [
    "## Price And Moving-Average Diagnostic\n",
    "\n",
    "This chart overlays each symbol's logged rebalance-date close with SMA(20/63/252), the exact ingredients used by the alpha model.\n",
    "Vertical guide lines mark signal direction flips (`Up` <-> `Down`) so you can inspect whether flips line up with price crossing one or more moving averages.\n",
    "\n",
    "Note: this uses `signals.csv` snapshots (rebalance observations), not full daily history.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portfolio_aggregate_diagnostics",
   "metadata": {},
   "source": [
    "## Portfolio Aggregate Diagnostics\n",
    "\n",
    "This section adds two portfolio-level time series:\n",
    "- **Portfolio turnover**: `0.5 * sum(|w_t - w_{t-1}|)` using `positions.csv` daily weights.\n",
    "- **Weighted average signal**: cross-sectional average of `signed_magnitude`, weighted by absolute portfolio weights on each signal date.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "k5zhcwqzuo",
   "source": [
    "## Latest Rebalance Signal Snapshot\n",
    "\n",
    "This table shows the signal snapshot from the most recent rebalance date, ranked by absolute magnitude, along with the individual short, medium, and long horizon contributions to each signal. It answers which symbols have the strongest current signals and which horizon is driving each signal the most. Use this table as an at-a-glance view of the portfolio's directional thesis going into the next scaling week."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_summary = (\n",
    "    df.groupby('symbol', as_index=False)\n",
    "      .agg(\n",
    "          signal_obs=('date', 'count'),\n",
    "          mean_abs_mag=('abs_magnitude', 'mean'),\n",
    "          median_abs_mag=('abs_magnitude', 'median'),\n",
    "          std_mag=('signed_magnitude', 'std'),\n",
    "          last_signal=('date', 'max'),\n",
    "          direction_flips=('direction_sign', lambda s: int((s.diff().fillna(0) != 0).sum()))\n",
    "      )\n",
    "      .sort_values(['signal_obs', 'mean_abs_mag'], ascending=[False, False])\n",
    ")\n",
    "\n",
    "display(symbol_summary.head(20))\n",
    "\n",
    "# Optional: set your own list, e.g. ['AAPL', 'MSFT', 'JPM']\n",
    "focus_symbols = []\n",
    "max_symbols = 12\n",
    "\n",
    "if focus_symbols:\n",
    "    symbols_to_plot = [s for s in focus_symbols if s in set(df['symbol'])]\n",
    "else:\n",
    "    symbols_to_plot = symbol_summary.head(max_symbols)['symbol'].tolist()\n",
    "\n",
    "print('Plotting symbols:', symbols_to_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not symbols_to_plot:\n",
    "    raise ValueError('No symbols selected for plotting.')\n",
    "\n",
    "heatmap_df = (\n",
    "    df[df['symbol'].isin(symbols_to_plot)]\n",
    "      .pivot(index='symbol', columns='date', values='signed_magnitude')\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "# Format dates and thin labels so the x-axis stays readable.\n",
    "date_labels = pd.to_datetime(heatmap_df.columns).strftime('%Y-%m-%d').tolist()\n",
    "max_xticks = 18\n",
    "step = max(1, len(date_labels) // max_xticks)\n",
    "xticklabels = [label if (i % step == 0) else '' for i, label in enumerate(date_labels)]\n",
    "\n",
    "plt.figure(figsize=(18, max(5, 0.55 * len(symbols_to_plot) + 2)))\n",
    "sns.heatmap(\n",
    "    heatmap_df,\n",
    "    cmap='RdYlGn',\n",
    "    center=0,\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    linewidths=0.0,\n",
    "    xticklabels=xticklabels,\n",
    "    cbar_kws={'label': 'Signed signal magnitude'}\n",
    ")\n",
    "plt.title('Signal Magnitude Heatmap by Symbol')\n",
    "plt.xlabel('Rebalance date')\n",
    "plt.ylabel('Symbol')\n",
    "plt.xticks(rotation=60, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(symbols_to_plot)\n",
    "cols = 3\n",
    "rows = int(np.ceil(n / cols))\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(18, max(4 * rows, 6)), sharex=True)\n",
    "axes = np.array(axes).reshape(-1)\n",
    "\n",
    "for i, symbol in enumerate(symbols_to_plot):\n",
    "    ax = axes[i]\n",
    "    ds = df[df['symbol'] == symbol].sort_values('date')\n",
    "\n",
    "    ax.plot(ds['date'], ds['signed_magnitude'], label='signed magnitude', color='#1f77b4', linewidth=1.6)\n",
    "    ax.plot(ds['date'], ds['implied_magnitude'], label=f'implied tanh(score / {SIGNAL_TEMPERATURE:g})', color='#ff7f0e', linewidth=1.1, alpha=0.85)\n",
    "    ax.axhline(0, color='black', linewidth=0.8, alpha=0.6)\n",
    "    ax.set_title(symbol)\n",
    "    ax.set_ylim(-1.05, 1.05)\n",
    "    ax.grid(alpha=0.25)\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', ncol=2, frameon=False)\n",
    "fig.suptitle('Per-Symbol Signal Path', y=0.995)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: inspect specific names, e.g. ['UNH']\n",
    "ma_focus_symbols = []\n",
    "max_ma_symbols = 6\n",
    "\n",
    "# Background shading controls:\n",
    "# green = long, red = short, darker = larger |signal|\n",
    "shade_signal_regime = True\n",
    "min_shade_alpha = 0.04\n",
    "max_shade_alpha = 0.24\n",
    "\n",
    "if ma_focus_symbols:\n",
    "    ma_symbols = [s for s in ma_focus_symbols if s in set(df['symbol'])]\n",
    "else:\n",
    "    ma_symbols = symbols_to_plot[:max_ma_symbols]\n",
    "\n",
    "if not ma_symbols:\n",
    "    raise ValueError('No symbols selected for price/SMA diagnostic plot.')\n",
    "\n",
    "print('Price/SMA diagnostic symbols:', ma_symbols)\n",
    "\n",
    "n = len(ma_symbols)\n",
    "cols = 2\n",
    "rows = int(np.ceil(n / cols))\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(18, max(4.5 * rows, 6)), sharex=True)\n",
    "axes = np.array(axes).reshape(-1)\n",
    "\n",
    "for i, symbol in enumerate(ma_symbols):\n",
    "    ax = axes[i]\n",
    "    ds = df[df['symbol'] == symbol].sort_values('date').reset_index(drop=True)\n",
    "\n",
    "    if shade_signal_regime and len(ds) > 0:\n",
    "        if len(ds) > 1:\n",
    "            typical_gap = ds['date'].diff().dropna().median()\n",
    "            if pd.isna(typical_gap) or typical_gap <= pd.Timedelta(0):\n",
    "                typical_gap = pd.Timedelta(days=5)\n",
    "        else:\n",
    "            typical_gap = pd.Timedelta(days=5)\n",
    "\n",
    "        for k in range(len(ds)):\n",
    "            start = ds.loc[k, 'date']\n",
    "            end = ds.loc[k + 1, 'date'] if k < len(ds) - 1 else start + typical_gap\n",
    "            m = float(ds.loc[k, 'signed_magnitude'])\n",
    "            m = max(-1.0, min(1.0, m))\n",
    "\n",
    "            color = plt.cm.RdYlGn((m + 1.0) / 2.0)\n",
    "            alpha = min_shade_alpha + (max_shade_alpha - min_shade_alpha) * min(1.0, abs(m))\n",
    "            ax.axvspan(start, end, color=color, alpha=alpha, linewidth=0, zorder=0)\n",
    "\n",
    "    ax.plot(ds['date'], ds['price'], label='Price', color='#222222', linewidth=1.9, zorder=3)\n",
    "    ax.plot(ds['date'], ds['sma_short'], label='SMA 20', color='#1f77b4', linewidth=1.2, zorder=3)\n",
    "    ax.plot(ds['date'], ds['sma_medium'], label='SMA 63', color='#ff7f0e', linewidth=1.2, zorder=3)\n",
    "    ax.plot(ds['date'], ds['sma_long'], label='SMA 252', color='#2ca02c', linewidth=1.2, zorder=3)\n",
    "\n",
    "    flip_mask = ds['direction_sign'].diff().fillna(0) != 0\n",
    "    flip_dates = ds.loc[flip_mask, 'date']\n",
    "    for d in flip_dates:\n",
    "        ax.axvline(d, color='#7f7f7f', alpha=0.16, linewidth=0.8, zorder=2)\n",
    "\n",
    "    flip_count = int(flip_mask.sum())\n",
    "    ax.set_title(f'{symbol} | flips={flip_count}')\n",
    "    ax.grid(alpha=0.25)\n",
    "\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "handles, labels = axes[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', ncol=4, frameon=False)\n",
    "fig.suptitle('Price + SMA Diagnostic (Rebalance Snapshots)', y=0.995)\n",
    "fig.text(0.5, 0.972, 'Background shading: green=long, red=short, darker=stronger |signal|', ha='center', va='center', fontsize=9, color='#444444')\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positions = read_csv_from_store(f'{TEAM_ID}/positions.csv')\n",
    "\n",
    "if df_positions is None or len(df_positions) == 0:\n",
    "    print('positions.csv not available; skipping portfolio aggregate diagnostics.')\n",
    "else:\n",
    "    pos = df_positions.copy()\n",
    "    required_pos_cols = ['date', 'symbol', 'weight']\n",
    "    missing_pos = [c for c in required_pos_cols if c not in pos.columns]\n",
    "    if missing_pos:\n",
    "        raise ValueError(f'positions.csv missing required columns: {missing_pos}')\n",
    "\n",
    "    pos['date'] = pd.to_datetime(pos['date'])\n",
    "    pos['weight'] = pd.to_numeric(pos['weight'], errors='coerce').fillna(0.0)\n",
    "    pos['symbol'] = pos['symbol'].astype(str)\n",
    "\n",
    "    # Keep one row per date/symbol in case of duplicates.\n",
    "    pos = (\n",
    "        pos.sort_values(['date', 'symbol'])\n",
    "           .drop_duplicates(['date', 'symbol'], keep='last')\n",
    "    )\n",
    "\n",
    "    weights_wide = (\n",
    "        pos.pivot(index='date', columns='symbol', values='weight')\n",
    "           .sort_index()\n",
    "           .fillna(0.0)\n",
    "    )\n",
    "\n",
    "    # Daily portfolio turnover in weight space.\n",
    "    daily_turnover = 0.5 * weights_wide.diff().abs().sum(axis=1)\n",
    "    daily_turnover = daily_turnover.fillna(0.0)\n",
    "    turnover_20d = daily_turnover.rolling(20, min_periods=5).mean()\n",
    "\n",
    "    sig = df[['date', 'symbol', 'signed_magnitude']].copy()\n",
    "    sig['date'] = pd.to_datetime(sig['date'])\n",
    "    sig['symbol'] = sig['symbol'].astype(str)\n",
    "\n",
    "    sig_w = sig.merge(\n",
    "        pos[['date', 'symbol', 'weight']],\n",
    "        on=['date', 'symbol'],\n",
    "        how='left'\n",
    "    )\n",
    "    sig_w['weight'] = pd.to_numeric(sig_w['weight'], errors='coerce').fillna(0.0)\n",
    "    sig_w['abs_weight'] = sig_w['weight'].abs()\n",
    "\n",
    "    denom = sig_w.groupby('date')['abs_weight'].sum()\n",
    "    numer_signed = (sig_w['signed_magnitude'] * sig_w['abs_weight']).groupby(sig_w['date']).sum()\n",
    "    numer_abs = (sig_w['signed_magnitude'].abs() * sig_w['abs_weight']).groupby(sig_w['date']).sum()\n",
    "\n",
    "    weighted_signal = pd.DataFrame({\n",
    "        'date': denom.index,\n",
    "        'gross_weight_on_signal_set': denom.values,\n",
    "        'weighted_avg_signal': np.where(denom.values > 0, numer_signed.values / denom.values, np.nan),\n",
    "        'weighted_avg_abs_signal': np.where(denom.values > 0, numer_abs.values / denom.values, np.nan),\n",
    "    })\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(16, 10), sharex=False)\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax.plot(daily_turnover.index, daily_turnover.values, color='#1f77b4', linewidth=1.1, alpha=0.8, label='Daily turnover')\n",
    "    ax.plot(turnover_20d.index, turnover_20d.values, color='#d62728', linewidth=2.0, label='20-day mean')\n",
    "    ax.set_title('Portfolio Weighted Turnover')\n",
    "    ax.set_ylabel('Turnover')\n",
    "    ax.grid(alpha=0.25)\n",
    "    ax.legend(frameon=False, loc='upper left')\n",
    "\n",
    "    ax = axes[1]\n",
    "    ws = weighted_signal.dropna(subset=['weighted_avg_signal']).sort_values('date')\n",
    "    ax.plot(ws['date'], ws['weighted_avg_signal'], color='#2c3e50', linewidth=1.8, marker='o', markersize=3, label='Weighted avg signal (signed)')\n",
    "    ax.plot(ws['date'], ws['weighted_avg_abs_signal'], color='#9467bd', linewidth=1.4, linestyle='--', alpha=0.9, label='Weighted avg |signal|')\n",
    "    ax.axhline(0, color='black', linewidth=0.8, alpha=0.6)\n",
    "    ax.fill_between(ws['date'], 0, ws['weighted_avg_signal'], where=(ws['weighted_avg_signal'] >= 0), color='#2ca02c', alpha=0.18, interpolate=True)\n",
    "    ax.fill_between(ws['date'], 0, ws['weighted_avg_signal'], where=(ws['weighted_avg_signal'] < 0), color='#d62728', alpha=0.18, interpolate=True)\n",
    "    ax.set_title('Portfolio Weighted Average Signal (Signal Dates)')\n",
    "    ax.set_ylabel('Signal')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_ylim(-1.05, 1.05)\n",
    "    ax.grid(alpha=0.25)\n",
    "    ax.legend(frameon=False, loc='upper left')\n",
    "\n",
    "    for a in axes:\n",
    "        locator = mdates.AutoDateLocator(minticks=6, maxticks=10)\n",
    "        a.xaxis.set_major_locator(locator)\n",
    "        a.xaxis.set_major_formatter(mdates.ConciseDateFormatter(locator))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_date = df['date'].max()\n",
    "latest = (\n",
    "    df[df['date'] == latest_date]\n",
    "      .sort_values('abs_magnitude', ascending=False)\n",
    "      [['date', 'symbol', 'signed_magnitude', 'contrib_short', 'contrib_medium', 'contrib_long']]\n",
    ")\n",
    "\n",
    "print(f'Latest rebalance date: {latest_date.date()}')\n",
    "display(latest.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}