{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order Lifecycle\n",
    "\n",
    "Lifecycle analytics using `wolfpack/order_events.csv`.\n",
    "\n",
    "This tracks:\n",
    "- Submitted, partially filled, filled, canceled counts\n",
    "- Fill ratio and time-to-final-status\n",
    "- Final status by execution tier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "from QuantConnect import *\n",
    "from QuantConnect.Research import QuantBook\n",
    "\n",
    "qb = QuantBook()\n",
    "print('QuantBook initialized')\n",
    "\n",
    "\n",
    "def read_csv_from_store(key):\n",
    "    try:\n",
    "        if not qb.ObjectStore.ContainsKey(key):\n",
    "            print(f'ObjectStore key not found: {key}')\n",
    "            return None\n",
    "        content = qb.ObjectStore.Read(key)\n",
    "        if not content:\n",
    "            print(f'Empty ObjectStore key: {key}')\n",
    "            return None\n",
    "        return pd.read_csv(StringIO(content))\n",
    "    except Exception as e:\n",
    "        print(f'Error reading {key}: {e}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tdtxlm9r5lm",
   "source": "## Data Loading — Order Events Log\n\nLoads the order events log from ObjectStore, parses tier and week-ID tags from the order annotation string, and displays the first few rows to confirm the schema. Each row represents one status update (submitted, partially filled, filled, cancelled) for a single order. The `tier` column inferred from tags is the key dimension used to segment all lifecycle statistics that follow.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "rjmgx8yg64f",
   "source": "## Order-Level Summary — Fill Ratio and Days to Final\n\nThis cell pivots from status-event rows to one row per order, computing fill ratio, days-to-final-status, and final outcome for each order ID. The resulting `order_summary` DataFrame is the primary analysis unit — one order with its full lifecycle condensed into a single record. The head preview confirms that `fill_ratio` and `days_to_final` are populated before charts are generated.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "r8edo90h94l",
   "source": "## Order Lifecycle — 4-Panel Chart\n\nThese four panels summarize the order lifecycle from submission to final resolution. Top-left shows counts by final status (filled, cancelled, etc.); top-right shows the fill-ratio distribution to reveal how often orders are only partially filled; bottom-left shows the final status mix as a stacked proportion by tier, testing whether high-tier orders fill more reliably; and bottom-right shows time-to-final-status by tier, checking whether strong-tier market-price limits resolve faster than wide weak-tier limits.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "axmmic7mfj5",
   "source": "## Cancel Rate and Fill Ratio Scorecard by Tier\n\nThis summary table reports cancel rate and average fill ratio for each signal tier, combining lifecycle performance into a compact scorecard. A higher cancel rate for weak-tier orders is expected given their 1.5% limit offset, but if strong-tier orders also show elevated cancels it may indicate the stale-limit cancellation threshold is too aggressive. Compare average fill ratios across tiers to confirm the tiered limit-offset design achieves meaningfully different fill outcomes.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "df_events = read_csv_from_store('wolfpack/order_events.csv')\n",
    "if df_events is None:\n",
    "    raise ValueError('order_events.csv is required. Run a backtest with order-event logging enabled.')\n",
    "\n",
    "df_events['date'] = pd.to_datetime(df_events['date'])\n",
    "for col in ['quantity', 'fill_quantity', 'fill_price', 'limit_price']:\n",
    "    if col in df_events.columns:\n",
    "        df_events[col] = pd.to_numeric(df_events[col], errors='coerce').fillna(0.0)\n",
    "\n",
    "def parse_tag_value(tag, key):\n",
    "    if pd.isna(tag):\n",
    "        return np.nan\n",
    "    m = re.search(rf'{key}=([^;]+)', str(tag))\n",
    "    return m.group(1) if m else np.nan\n",
    "\n",
    "df_events['tier'] = df_events['tag'].apply(lambda t: parse_tag_value(t, 'tier')).fillna('unknown')\n",
    "df_events['week_id'] = df_events['tag'].apply(lambda t: parse_tag_value(t, 'week_id')).fillna('')\n",
    "\n",
    "print(f'order events: {len(df_events):,}')\n",
    "display(df_events.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate each order lifecycle\n",
    "grp = df_events.sort_values('date').groupby('order_id', as_index=False)\n",
    "\n",
    "order_summary = grp.agg(\n",
    "    symbol=('symbol', 'first'),\n",
    "    tier=('tier', 'first'),\n",
    "    order_type=('order_type', 'first'),\n",
    "    quantity=('quantity', 'first'),\n",
    "    submitted_at=('date', 'min'),\n",
    "    final_at=('date', 'max')\n",
    ")\n",
    "\n",
    "final_status = (\n",
    "    df_events.sort_values('date')\n",
    "             .groupby('order_id')\n",
    "             .tail(1)[['order_id', 'status']]\n",
    "             .rename(columns={'status': 'final_status'})\n",
    ")\n",
    "\n",
    "fills = (\n",
    "    df_events.groupby('order_id', as_index=False)['fill_quantity']\n",
    "             .sum()\n",
    "             .rename(columns={'fill_quantity': 'filled_qty'})\n",
    ")\n",
    "\n",
    "order_summary = order_summary.merge(final_status, on='order_id', how='left')\n",
    "order_summary = order_summary.merge(fills, on='order_id', how='left')\n",
    "\n",
    "order_summary['abs_qty'] = order_summary['quantity'].abs().replace(0, np.nan)\n",
    "order_summary['fill_ratio'] = (order_summary['filled_qty'].abs() / order_summary['abs_qty']).fillna(0.0).clip(0, 1)\n",
    "order_summary['days_to_final'] = (order_summary['final_at'] - order_summary['submitted_at']).dt.days.fillna(0)\n",
    "\n",
    "display(order_summary.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "status_counts = order_summary['final_status'].value_counts().sort_values(ascending=False)\n",
    "status_counts.plot(kind='bar', ax=axes[0, 0], color='#1f77b4')\n",
    "axes[0, 0].set_title('Final Order Status Counts')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "sns.histplot(order_summary['fill_ratio'], bins=20, ax=axes[0, 1], color='#2ca02c')\n",
    "axes[0, 1].set_title('Fill Ratio Distribution')\n",
    "axes[0, 1].set_xlabel('Fill ratio')\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "tier_status = pd.crosstab(order_summary['tier'], order_summary['final_status'], normalize='index')\n",
    "tier_status = tier_status.reindex(['strong', 'moderate', 'weak', 'exit', 'unknown']).dropna(how='all')\n",
    "tier_status.plot(kind='bar', stacked=True, ax=axes[1, 0], colormap='tab20')\n",
    "axes[1, 0].set_title('Final Status Mix by Tier')\n",
    "axes[1, 0].set_ylabel('Share')\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "sns.boxplot(data=order_summary, x='tier', y='days_to_final', order=['strong', 'moderate', 'weak', 'exit', 'unknown'], ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Days to Final Status by Tier')\n",
    "axes[1, 1].set_xlabel('Tier')\n",
    "axes[1, 1].set_ylabel('Days')\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancel_rate = (\n",
    "    order_summary.assign(is_canceled=order_summary['final_status'].astype(str).str.contains('Canceled', case=False, na=False))\n",
    "                .groupby('tier', as_index=False)\n",
    "                .agg(orders=('order_id', 'count'),\n",
    "                     cancel_rate=('is_canceled', 'mean'),\n",
    "                     avg_fill_ratio=('fill_ratio', 'mean'))\n",
    "                .sort_values('orders', ascending=False)\n",
    ")\n",
    "display(cancel_rate)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}