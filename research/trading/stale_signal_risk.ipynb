{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stale Signal Risk\n",
    "\n",
    "Measure how market movement evolves after rebalance while targets are still being scaled.\n",
    "\n",
    "Uses:\n",
    "- `targets.csv` for week/day mapping\n",
    "- `positions.csv` for daily prices/weights\n",
    "- `signals.csv` for rebalance-day signal magnitude (tier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "from QuantConnect import *\n",
    "from QuantConnect.Research import QuantBook\n",
    "\n",
    "qb = QuantBook()\n",
    "print('QuantBook initialized')\n",
    "\n",
    "\n",
    "def read_csv_from_store(key):\n",
    "    try:\n",
    "        if not qb.ObjectStore.ContainsKey(key):\n",
    "            print(f'ObjectStore key not found: {key}')\n",
    "            return None\n",
    "        content = qb.ObjectStore.Read(key)\n",
    "        if not content:\n",
    "            print(f'Empty ObjectStore key: {key}')\n",
    "            return None\n",
    "        return pd.read_csv(StringIO(content))\n",
    "    except Exception as e:\n",
    "        print(f'Error reading {key}: {e}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6xv1v9lbvzs",
   "source": "## Data Loading & Adverse Move Setup\n\nLoads targets, positions, and signals data, then joins daily prices onto the target schedule to compute a reference price at the start of each rebalance week. The `adverse_move` column measures how much each stock moved against the intended trade direction during the scaling window, and `tier` segments results by signal strength. The head preview confirms all join columns are populated before analysis proceeds.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "9swpw0om66",
   "source": "## Adverse Move and PnL Profiles During Scaling\n\nThese two line charts profile market movement and P&L during the scaling period, broken out by signal tier and indexed by day-in-week. The left chart shows mean adverse price move since rebalance â€” a rising line means the stock is increasingly moving against the unfilled portion of the order. The right chart shows mean daily net P&L during the scaling window, revealing whether delayed filling is associated with weaker realized returns.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "ehfar0k7jho",
   "source": "## Weekly Stale Signal Risk Summary Table\n\nThis table summarizes stale-signal risk at the week level, reporting average and maximum adverse move along with total net P&L for each rebalance cycle. Weeks with high `max_adverse_move` coupled with low `week_net_pnl` identify periods where slow fill execution genuinely hurt performance. Use this table to correlate stale-signal risk with broader market conditions such as trend reversals or elevated volatility regimes.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_targets = read_csv_from_store('wolfpack/targets.csv')\n",
    "df_positions = read_csv_from_store('wolfpack/positions.csv')\n",
    "df_signals = read_csv_from_store('wolfpack/signals.csv')\n",
    "\n",
    "if df_targets is None or df_positions is None:\n",
    "    raise ValueError('targets.csv and positions.csv are required.')\n",
    "\n",
    "df_targets['date'] = pd.to_datetime(df_targets['date'])\n",
    "df_positions['date'] = pd.to_datetime(df_positions['date'])\n",
    "\n",
    "for col in ['start_w', 'weekly_target_w', 'actual_w']:\n",
    "    df_targets[col] = pd.to_numeric(df_targets[col], errors='coerce').fillna(0.0)\n",
    "for col in ['price', 'daily_total_net_pnl']:\n",
    "    if col in df_positions.columns:\n",
    "        df_positions[col] = pd.to_numeric(df_positions[col], errors='coerce')\n",
    "\n",
    "px = (\n",
    "    df_positions[['date', 'symbol', 'price', 'daily_total_net_pnl']]\n",
    "    .dropna(subset=['price'])\n",
    "    .drop_duplicates(['date', 'symbol'])\n",
    "    .sort_values(['symbol', 'date'])\n",
    ")\n",
    "\n",
    "tgt = df_targets[['date', 'week_id', 'symbol', 'start_w', 'weekly_target_w', 'actual_w']].drop_duplicates()\n",
    "merged = tgt.merge(px, on=['date', 'symbol'], how='left')\n",
    "\n",
    "# Rebalance-day price reference\n",
    "rebalance_px = (\n",
    "    merged.sort_values('date')\n",
    "          .groupby(['week_id', 'symbol'], as_index=False)\n",
    "          .first()[['week_id', 'symbol', 'price']]\n",
    "          .rename(columns={'price': 'rebalance_price'})\n",
    ")\n",
    "merged = merged.merge(rebalance_px, on=['week_id', 'symbol'], how='left')\n",
    "\n",
    "merged['day_in_week'] = merged.sort_values('date').groupby(['week_id', 'symbol']).cumcount()\n",
    "merged['signal_direction'] = np.sign(merged['weekly_target_w']).replace(0, np.nan)\n",
    "merged['return_since_rebalance'] = (merged['price'] / merged['rebalance_price']) - 1.0\n",
    "merged['adverse_move'] = -merged['signal_direction'] * merged['return_since_rebalance']\n",
    "\n",
    "if df_signals is not None:\n",
    "    df_signals['date'] = pd.to_datetime(df_signals['date'])\n",
    "    df_signals['week_id'] = df_signals['date'].dt.strftime('%Y-%m-%d')\n",
    "    df_signals['mag_abs'] = pd.to_numeric(df_signals['magnitude'], errors='coerce').fillna(0.0).abs()\n",
    "    sig = df_signals[['week_id', 'symbol', 'mag_abs']].drop_duplicates(['week_id', 'symbol'])\n",
    "    merged = merged.merge(sig, on=['week_id', 'symbol'], how='left')\n",
    "else:\n",
    "    merged['mag_abs'] = np.nan\n",
    "\n",
    "def tier(m):\n",
    "    if pd.isna(m):\n",
    "        return 'unknown'\n",
    "    if m >= 0.7:\n",
    "        return 'strong'\n",
    "    if m >= 0.3:\n",
    "        return 'moderate'\n",
    "    return 'weak'\n",
    "\n",
    "merged['tier'] = merged['mag_abs'].apply(tier)\n",
    "display(merged.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = (\n",
    "    merged.groupby(['tier', 'day_in_week'], as_index=False)\n",
    "          .agg(\n",
    "              mean_adverse_move=('adverse_move', 'mean'),\n",
    "              median_adverse_move=('adverse_move', 'median'),\n",
    "              mean_daily_net_pnl=('daily_total_net_pnl', 'mean')\n",
    "          )\n",
    ")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "sns.lineplot(data=profile, x='day_in_week', y='mean_adverse_move', hue='tier', marker='o', ax=axes[0])\n",
    "axes[0].axhline(0, color='black', linewidth=1)\n",
    "axes[0].set_title('Mean Adverse Move Since Rebalance')\n",
    "axes[0].set_ylabel('Adverse move (fraction)')\n",
    "axes[0].set_xlabel('Day-in-week')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "sns.lineplot(data=profile, x='day_in_week', y='mean_daily_net_pnl', hue='tier', marker='o', ax=axes[1])\n",
    "axes[1].axhline(0, color='black', linewidth=1)\n",
    "axes[1].set_title('Mean Daily Net PnL During Scaling')\n",
    "axes[1].set_ylabel('Daily net PnL ($)')\n",
    "axes[1].set_xlabel('Day-in-week')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "week_risk = (\n",
    "    merged.groupby('week_id', as_index=False)\n",
    "          .agg(\n",
    "              avg_adverse_move=('adverse_move', 'mean'),\n",
    "              max_adverse_move=('adverse_move', 'max'),\n",
    "              week_net_pnl=('daily_total_net_pnl', 'sum')\n",
    "          )\n",
    "          .sort_values('week_id')\n",
    ")\n",
    "display(week_risk.tail(15))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}