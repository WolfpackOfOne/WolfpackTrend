{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation Risk\n",
    "\n",
    "Assess concentration to shared moves across symbols using rolling return correlations.\n",
    "\n",
    "**Data Source:**\n",
    "- `wolfpack/positions.csv` - daily symbol price and portfolio weight\n",
    "\n",
    "**Analysis:**\n",
    "- Build a symbol return matrix from position history\n",
    "- Rolling pairwise correlation metrics (20/60/252 days)\n",
    "- Latest correlation heatmap for top-exposure symbols\n",
    "- Highest-correlation symbol pairs\n",
    "\n",
    "**Prerequisites:** Run a WolfpackTrend backtest with position logging enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "from QuantConnect import *\n",
    "from QuantConnect.Research import QuantBook\n",
    "\n",
    "qb = QuantBook()\n",
    "print('QuantBook initialized')\n",
    "\n",
    "\n",
    "def read_csv_from_store(key):\n",
    "    try:\n",
    "        if not qb.ObjectStore.ContainsKey(key):\n",
    "            print(f'ObjectStore key not found: {key}')\n",
    "            return None\n",
    "        content = qb.ObjectStore.Read(key)\n",
    "        if not content:\n",
    "            print(f'Empty ObjectStore key: {key}')\n",
    "            return None\n",
    "        return pd.read_csv(StringIO(content))\n",
    "    except Exception as e:\n",
    "        print(f'Error reading {key}: {e}')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Position Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positions = read_csv_from_store('wolfpack/positions.csv')\n",
    "\n",
    "if df_positions is None:\n",
    "    raise ValueError('positions.csv is required. Run a backtest with position logging enabled.')\n",
    "\n",
    "symbol_col = None\n",
    "for col in ['symbol', 'ticker', 'underlying']:\n",
    "    if col in df_positions.columns:\n",
    "        symbol_col = col\n",
    "        break\n",
    "\n",
    "weight_col = None\n",
    "for col in ['weight', 'portfolio_weight', 'actual_w']:\n",
    "    if col in df_positions.columns:\n",
    "        weight_col = col\n",
    "        break\n",
    "\n",
    "if symbol_col is None:\n",
    "    raise ValueError('Could not find symbol column in positions.csv (expected one of: symbol, ticker, underlying).')\n",
    "if weight_col is None:\n",
    "    raise ValueError('Could not find weight column in positions.csv (expected one of: weight, portfolio_weight, actual_w).')\n",
    "if 'price' not in df_positions.columns:\n",
    "    raise ValueError('positions.csv missing required price column for return calculation.')\n",
    "\n",
    "df = df_positions[['date', symbol_col, weight_col, 'price']].copy()\n",
    "df.columns = ['date', 'symbol', 'weight', 'price']\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['weight'] = pd.to_numeric(df['weight'], errors='coerce').fillna(0.0)\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "\n",
    "df = df.dropna(subset=['date', 'symbol', 'price'])\n",
    "df = df.sort_values(['symbol', 'date']).reset_index(drop=True)\n",
    "\n",
    "print(f'Loaded {len(df):,} position rows')\n",
    "print(f'Date range: {df.date.min().strftime(\"%Y-%m-%d\")} to {df.date.max().strftime(\"%Y-%m-%d\")}')\n",
    "print(f'Symbols: {df.symbol.nunique()}')\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Return Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['symbol_return'] = df.groupby('symbol')['price'].pct_change()\n",
    "\n",
    "panel = df.dropna(subset=['symbol_return']).copy()\n",
    "panel = panel[(panel['symbol_return'] > -0.9) & (panel['symbol_return'] < 0.9)]\n",
    "\n",
    "if panel.empty:\n",
    "    raise ValueError('No usable symbol returns after cleaning. Check price history in positions.csv.')\n",
    "\n",
    "top_symbols = (\n",
    "    panel.groupby('symbol')['weight']\n",
    "         .apply(lambda s: s.abs().mean())\n",
    "         .sort_values(ascending=False)\n",
    "         .head(20)\n",
    "         .index\n",
    "         .tolist()\n",
    ")\n",
    "\n",
    "panel = panel[panel['symbol'].isin(top_symbols)].copy()\n",
    "\n",
    "returns_wide = (\n",
    "    panel.pivot_table(index='date', columns='symbol', values='symbol_return', aggfunc='last')\n",
    "         .sort_index()\n",
    ")\n",
    "\n",
    "weights_wide = (\n",
    "    panel.pivot_table(index='date', columns='symbol', values='weight', aggfunc='last')\n",
    "         .sort_index()\n",
    "         .reindex(returns_wide.index)\n",
    "         .fillna(0.0)\n",
    ")\n",
    "\n",
    "print(f'Return matrix shape: {returns_wide.shape[0]} days x {returns_wide.shape[1]} symbols')\n",
    "display(returns_wide.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Correlation Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_corr_metrics(returns_frame, windows=(20, 60, 252)):\n",
    "    metrics = []\n",
    "\n",
    "    for window in windows:\n",
    "        if len(returns_frame) < window:\n",
    "            continue\n",
    "\n",
    "        for end_idx in range(window - 1, len(returns_frame)):\n",
    "            date = returns_frame.index[end_idx]\n",
    "            window_slice = returns_frame.iloc[end_idx - window + 1:end_idx + 1]\n",
    "\n",
    "            valid = window_slice.dropna(axis=1, thresh=max(10, int(window * 0.8)))\n",
    "            if valid.shape[1] < 2:\n",
    "                continue\n",
    "\n",
    "            corr = valid.corr()\n",
    "            mask = np.triu(np.ones(corr.shape, dtype=bool), k=1)\n",
    "            pairwise = corr.where(mask).stack()\n",
    "\n",
    "            if pairwise.empty:\n",
    "                continue\n",
    "\n",
    "            metrics.append({\n",
    "                'date': date,\n",
    "                'window': window,\n",
    "                'symbols_used': valid.shape[1],\n",
    "                'mean_pairwise_corr': pairwise.mean(),\n",
    "                'mean_abs_corr': pairwise.abs().mean(),\n",
    "                'max_abs_corr': pairwise.abs().max()\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "\n",
    "metrics_df = rolling_corr_metrics(returns_wide)\n",
    "\n",
    "if metrics_df.empty:\n",
    "    print('No rolling correlation metrics available (insufficient history).')\n",
    "else:\n",
    "    display(metrics_df.tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Correlation Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not metrics_df.empty:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(14, 10), sharex=True)\n",
    "\n",
    "    for window in sorted(metrics_df['window'].unique()):\n",
    "        subset = metrics_df[metrics_df['window'] == window]\n",
    "        axes[0].plot(subset['date'], subset['mean_abs_corr'], label=f'{window}-day', linewidth=2)\n",
    "        axes[1].plot(subset['date'], subset['max_abs_corr'], label=f'{window}-day', linewidth=2)\n",
    "\n",
    "    axes[0].set_title('Rolling Mean Absolute Pairwise Correlation', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('Mean |Correlation|')\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    axes[0].legend(loc='upper left')\n",
    "\n",
    "    axes[1].set_title('Rolling Max Absolute Pairwise Correlation', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Date')\n",
    "    axes[1].set_ylabel('Max |Correlation|')\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    axes[1].legend(loc='upper left')\n",
    "\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latest Heatmap and Top Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 60 if len(returns_wide) >= 60 else 20\n",
    "\n",
    "if len(returns_wide) >= window:\n",
    "    recent = returns_wide.tail(window).dropna(axis=1, thresh=max(5, int(window * 0.7)))\n",
    "\n",
    "    if recent.shape[1] >= 2:\n",
    "        corr = recent.corr()\n",
    "\n",
    "        latest_weights = weights_wide.reindex(columns=corr.columns).tail(1).T.squeeze()\n",
    "        latest_weights = latest_weights.abs().sort_values(ascending=False)\n",
    "        order = latest_weights.index.tolist()\n",
    "\n",
    "        corr = corr.reindex(index=order, columns=order)\n",
    "\n",
    "        plt.figure(figsize=(12, 9))\n",
    "        sns.heatmap(corr, cmap='RdBu_r', vmin=-1, vmax=1, center=0, linewidths=0.4)\n",
    "        plt.title(f'Latest {window}-Day Correlation Matrix (Top Exposure Symbols)', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        pairwise = corr.where(np.triu(np.ones(corr.shape, dtype=bool), k=1)).stack().reset_index()\n",
    "        pairwise.columns = ['symbol_a', 'symbol_b', 'correlation']\n",
    "        pairwise['abs_correlation'] = pairwise['correlation'].abs()\n",
    "\n",
    "        top_pairs = pairwise.sort_values('abs_correlation', ascending=False).head(15)\n",
    "        print('Top correlation pairs:')\n",
    "        display(top_pairs)\n",
    "    else:\n",
    "        print('Not enough symbols with valid history to build a correlation heatmap.')\n",
    "else:\n",
    "    print('Insufficient history for the selected heatmap window.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not metrics_df.empty:\n",
    "    latest_summary = (\n",
    "        metrics_df.sort_values('date')\n",
    "                  .groupby('window', as_index=False)\n",
    "                  .tail(1)\n",
    "                  .sort_values('window')\n",
    "    )\n",
    "\n",
    "    display(latest_summary[['window', 'date', 'symbols_used', 'mean_pairwise_corr', 'mean_abs_corr', 'max_abs_corr']])\n",
    "\n",
    "    latest_row = latest_summary[latest_summary['window'] == latest_summary['window'].max()].iloc[-1]\n",
    "    print('\\nCorrelation risk snapshot:')\n",
    "    print(f\"  Window: {int(latest_row['window'])} days\")\n",
    "    print(f\"  Symbols used: {int(latest_row['symbols_used'])}\")\n",
    "    print(f\"  Mean abs correlation: {latest_row['mean_abs_corr']:.3f}\")\n",
    "    print(f\"  Max abs correlation: {latest_row['max_abs_corr']:.3f}\")\n",
    "else:\n",
    "    print('No summary available due to insufficient rolling-correlation observations.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}