{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Signal Profitability Stats\n",
    "\n",
    "This notebook measures how predictive your logged signals are using forward returns.\n",
    "\n",
    "Questions it answers:\n",
    "- Do strong/moderate/weak signals have different realized edge?\n",
    "- Which horizons (1d / 3d / 5d) carry the best signal quality?\n",
    "- Which symbols and magnitude buckets are most/least profitable?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from io import StringIO\n",
    "from IPython.display import display\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "from QuantConnect import *\n",
    "from QuantConnect.Research import QuantBook\n",
    "\n",
    "qb = QuantBook()\n",
    "print('QuantBook initialized')\n",
    "\n",
    "\n",
    "def read_csv_from_store(key):\n",
    "    try:\n",
    "        if not qb.ObjectStore.ContainsKey(key):\n",
    "            print(f'ObjectStore key not found: {key}')\n",
    "            return None\n",
    "        content = qb.ObjectStore.Read(key)\n",
    "        if not content:\n",
    "            print(f'Empty ObjectStore key: {key}')\n",
    "            return None\n",
    "        return pd.read_csv(StringIO(content))\n",
    "    except Exception as e:\n",
    "        print(f'Error reading {key}: {e}')\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_signals = read_csv_from_store('wolfpack/signals.csv')\n",
    "df_positions = read_csv_from_store('wolfpack/positions.csv')\n",
    "\n",
    "if df_signals is None:\n",
    "    raise ValueError('signals.csv is required. Run a backtest with signal logging enabled.')\n",
    "\n",
    "required_cols = ['date', 'symbol', 'direction', 'magnitude', 'price']\n",
    "missing = [c for c in required_cols if c not in df_signals.columns]\n",
    "if missing:\n",
    "    raise ValueError(f'signals.csv missing required columns: {missing}')\n",
    "\n",
    "signals = df_signals.copy()\n",
    "signals['date'] = pd.to_datetime(signals['date'])\n",
    "for col in ['magnitude', 'price']:\n",
    "    signals[col] = pd.to_numeric(signals[col], errors='coerce')\n",
    "\n",
    "signals['direction'] = signals['direction'].astype(str).str.title()\n",
    "signals['direction_sign'] = np.where(signals['direction'].eq('Up'), 1.0, -1.0)\n",
    "signals['abs_magnitude'] = signals['magnitude'].abs()\n",
    "signals['tier'] = np.select(\n",
    "    [signals['abs_magnitude'] >= 0.7, signals['abs_magnitude'] >= 0.3],\n",
    "    ['strong', 'moderate'],\n",
    "    default='weak'\n",
    ")\n",
    "\n",
    "price_parts = [\n",
    "    signals[['date', 'symbol', 'price']].assign(source='signals', source_priority=1)\n",
    "]\n",
    "\n",
    "if df_positions is not None and {'date', 'symbol', 'price'}.issubset(df_positions.columns):\n",
    "    pos_px = df_positions[['date', 'symbol', 'price']].copy()\n",
    "    pos_px['date'] = pd.to_datetime(pos_px['date'])\n",
    "    pos_px['price'] = pd.to_numeric(pos_px['price'], errors='coerce')\n",
    "    price_parts.append(pos_px.assign(source='positions', source_priority=0))\n",
    "\n",
    "prices = pd.concat(price_parts, ignore_index=True)\n",
    "prices = prices.dropna(subset=['date', 'symbol', 'price'])\n",
    "prices = prices.sort_values(['symbol', 'date', 'source_priority'])\n",
    "prices = prices.drop_duplicates(['symbol', 'date'], keep='first')\n",
    "prices = prices.sort_values(['symbol', 'date'])\n",
    "\n",
    "horizons = [1, 3, 5]\n",
    "for h in horizons:\n",
    "    prices[f'fwd_price_{h}d'] = prices.groupby('symbol')['price'].shift(-h)\n",
    "    prices[f'fwd_ret_{h}d'] = prices[f'fwd_price_{h}d'] / prices['price'] - 1.0\n",
    "\n",
    "merge_cols = ['date', 'symbol'] + [f'fwd_ret_{h}d' for h in horizons]\n",
    "df = signals.merge(prices[merge_cols], on=['date', 'symbol'], how='left')\n",
    "\n",
    "for h in horizons:\n",
    "    df[f'signed_ret_{h}d'] = df['direction_sign'] * df[f'fwd_ret_{h}d']\n",
    "\n",
    "coverage = {\n",
    "    f'{h}d_coverage': float(df[f'signed_ret_{h}d'].notna().mean())\n",
    "    for h in horizons\n",
    "}\n",
    "print(f\"signal rows: {len(df):,}\")\n",
    "print('forward-return coverage:', {k: f'{v:.1%}' for k, v in coverage.items()})\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tier_order = ['strong', 'moderate', 'weak']\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "sns.boxplot(data=df, x='tier', y='signed_ret_1d', order=tier_order, ax=axes[0])\n",
    "axes[0].axhline(0, color='black', linewidth=1)\n",
    "axes[0].set_title('Signed 1D Return by Tier')\n",
    "axes[0].set_xlabel('Tier')\n",
    "axes[0].set_ylabel('Signed return')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "means = (\n",
    "    df.groupby('tier')[[f'signed_ret_{h}d' for h in [1, 3, 5]]]\n",
    "      .mean()\n",
    "      .reindex(tier_order)\n",
    ")\n",
    "for tier in tier_order:\n",
    "    if tier not in means.index:\n",
    "        continue\n",
    "    axes[1].plot([1, 3, 5], means.loc[tier].values, marker='o', label=tier)\n",
    "axes[1].axhline(0, color='black', linewidth=1)\n",
    "axes[1].set_title('Average Signed Return by Horizon')\n",
    "axes[1].set_xlabel('Horizon (days)')\n",
    "axes[1].set_ylabel('Mean signed return')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "sns.histplot(df['signed_ret_5d'].dropna(), bins=35, kde=True, ax=axes[2], color='#ff7f0e')\n",
    "axes[2].axvline(0, color='black', linewidth=1)\n",
    "axes[2].set_title('Signed 5D Return Distribution')\n",
    "axes[2].set_xlabel('Signed 5D return')\n",
    "axes[2].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for tier, grp in df.groupby('tier'):\n",
    "    for h in [1, 3, 5]:\n",
    "        col = f'signed_ret_{h}d'\n",
    "        x = grp[col].dropna()\n",
    "        n = len(x)\n",
    "        hit = (x > 0).mean() if n else np.nan\n",
    "        avg = x.mean() if n else np.nan\n",
    "        med = x.median() if n else np.nan\n",
    "        std = x.std(ddof=1) if n > 1 else np.nan\n",
    "        t_stat = (avg / (std / np.sqrt(n))) if (n > 1 and std and std > 0) else np.nan\n",
    "        records.append({\n",
    "            'tier': tier,\n",
    "            'horizon_days': h,\n",
    "            'signals': n,\n",
    "            'hit_rate': hit,\n",
    "            'avg_signed_return': avg,\n",
    "            'median_signed_return': med,\n",
    "            't_stat': t_stat,\n",
    "        })\n",
    "\n",
    "edge_by_tier = pd.DataFrame(records).sort_values(['horizon_days', 'tier'])\n",
    "edge_by_tier['hit_rate'] = 100 * edge_by_tier['hit_rate']\n",
    "\n",
    "bucket_n = min(5, int(df['abs_magnitude'].nunique()))\n",
    "if bucket_n >= 2:\n",
    "    df['magnitude_bucket'] = pd.qcut(df['abs_magnitude'], q=bucket_n, duplicates='drop')\n",
    "    bucket_summary = (\n",
    "        df.groupby('magnitude_bucket', as_index=False)\n",
    "          .agg(\n",
    "              signals=('signed_ret_5d', 'count'),\n",
    "              hit_rate_5d=('signed_ret_5d', lambda s: (s > 0).mean()),\n",
    "              avg_signed_ret_5d=('signed_ret_5d', 'mean'),\n",
    "              median_signed_ret_5d=('signed_ret_5d', 'median')\n",
    "          )\n",
    "          .sort_values('magnitude_bucket')\n",
    "    )\n",
    "    bucket_summary['hit_rate_5d'] = 100 * bucket_summary['hit_rate_5d']\n",
    "else:\n",
    "    bucket_summary = pd.DataFrame()\n",
    "\n",
    "symbol_edge = (\n",
    "    df.groupby('symbol', as_index=False)\n",
    "      .agg(\n",
    "          signals=('signed_ret_5d', 'count'),\n",
    "          hit_rate_5d=('signed_ret_5d', lambda s: (s > 0).mean()),\n",
    "          avg_signed_ret_5d=('signed_ret_5d', 'mean')\n",
    "      )\n",
    ")\n",
    "symbol_edge = symbol_edge[symbol_edge['signals'] >= 5].sort_values('avg_signed_ret_5d', ascending=False)\n",
    "symbol_edge['hit_rate_5d'] = 100 * symbol_edge['hit_rate_5d']\n",
    "\n",
    "print('Edge by tier and horizon')\n",
    "display(edge_by_tier)\n",
    "\n",
    "if not bucket_summary.empty:\n",
    "    print('Edge by |magnitude| bucket (5D signed return)')\n",
    "    display(bucket_summary)\n",
    "\n",
    "print('Top symbols by 5D signal edge (min 5 observations)')\n",
    "display(symbol_edge.head(10))\n",
    "\n",
    "print('Bottom symbols by 5D signal edge (min 5 observations)')\n",
    "display(symbol_edge.tail(10).sort_values('avg_signed_ret_5d'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_edge = (\n",
    "    df.dropna(subset=['signed_ret_5d'])\n",
    "      .groupby('date', as_index=False)\n",
    "      .agg(mean_signed_ret_5d=('signed_ret_5d', 'mean'))\n",
    "      .sort_values('date')\n",
    ")\n",
    "\n",
    "if not daily_edge.empty:\n",
    "    daily_edge['cum_signal_edge'] = (1 + daily_edge['mean_signed_ret_5d']).cumprod() - 1\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    ax.plot(daily_edge['date'], 100 * daily_edge['cum_signal_edge'], color='#2ca02c', linewidth=2)\n",
    "    ax.axhline(0, color='black', linewidth=1)\n",
    "    ax.set_title('Cumulative Mean 5D Signed Signal Return (Illustrative)')\n",
    "    ax.set_ylabel('Cumulative return (%)')\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".NET (C#)",
   "language": "C#",
   "name": ".net-csharp"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}